{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outline.\n",
    "            1. Frequency Base Embedding\n",
    "            \n",
    "            2. Prediction Base Embedding.\n",
    "            \n",
    "            3. Word Embedding: Word2vec & GloVe\n",
    "            \n",
    "            4. Keras Embedding Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Frequency Base Embedding\n",
    "\n",
    "Includes: `Count Vector`; `tf-idf Vector` and `Co-occurrence Matrix.`\n",
    "\n",
    "### 1.1. CountVectorizer using with `TfidfTransformer` \n",
    "\n",
    "First, consider the simple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 sentences in this corpus\n",
      "The number of the different words is : 11 , and ... they are:\n",
      "['and', 'document', 'first', 'is', 'not', 'one', 'second', 'the', 'third', 'this', 'yours']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['this is the first document',\n",
    "          'this document is the second document',\n",
    "          'and this is the third one',\n",
    "          'is this the first document?',\n",
    "          'this Document is not yours..']\n",
    "\n",
    "cvect = CountVectorizer()\n",
    "X = cvect.fit_transform(corpus)\n",
    "\n",
    "print(\"There are %d sentences in this corpus\"%(X.shape[0]))\n",
    "print('The number of the different words is :', X.shape[1], \", and ... they are:\")\n",
    "print(cvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Firstly, they will count how many `different words` in this sentence, here are `11`; noting that both of the words \"`document`\" and \"`Document`\" will be changed to the lower scripts : `\"Document\"`.\n",
    "- Only the second document contains the `word has frequencies = 2`, it is `document`.\n",
    "- The `unique` words in the corpus will be arranged to the `English alphabet characters`; starting at the word \"**a**nd\" and ending by \"**y**ours\".\n",
    "- The `punctuation` (such as `\"?\"` or `\"!\"`, ....) will be ignored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 2, 0, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vocabulary = cvect.get_feature_names()\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary = vocabulary, min_df=2, max_df=0.5, ngram_range=(1,2))),\n",
    "                 ('tfid', TfidfTransformer(smooth_idf=False, use_idf=True))]).fit(corpus)\n",
    "pipe['count'].transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, **compute the `IDF` values.** (An `idf` is constant per corpus, and **accounts** for the ratio of documents that include the word.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea_names</th>\n",
       "      <th>idf_smooth_False)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>2.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document</td>\n",
       "      <td>1.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not</td>\n",
       "      <td>2.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>2.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>second</td>\n",
       "      <td>2.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>1.223144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>third</td>\n",
       "      <td>2.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yours</td>\n",
       "      <td>2.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fea_names  idf_smooth_False)\n",
       "0        and           2.609438\n",
       "1   document           1.223144\n",
       "2      first           1.916291\n",
       "3         is           1.000000\n",
       "4        not           2.609438\n",
       "5        one           2.609438\n",
       "6     second           2.609438\n",
       "7        the           1.223144\n",
       "8      third           2.609438\n",
       "9       this           1.000000\n",
       "10     yours           2.609438"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame({\"fea_names\": cvect.get_feature_names(), \"idf_smooth_False)\": pipe['tfid'].idf_})\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py#L987-L992 and https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html?highlight=tfidf#sklearn.feature_extraction.text.TfidfTransformer\n",
    "\n",
    "- If `smooth_idf=False`); the formula that is used to compute the `tf-idf` for a term t of a document `d` in a document set is \n",
    "\n",
    "                                    tf-idf(w, d) = tf(w, d) * idf(w), \n",
    "\n",
    "and the `idf` is computed as \n",
    "\n",
    "                                        idf(w) = log [ n / df(w) ] + 1, \n",
    "\n",
    "where `n` is the `total number of documents in the corpus` and `df(t) is the document frequency of w`; the document frequency is the number of documents in the document set that contain the word `w`. \n",
    "\n",
    "The effect of adding `“1”` to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, ***will not be entirely ignored***. \n",
    "\n",
    "For example: \n",
    "1. The word `\"can\"`. We have a corpus of `5 sentences/ documents` and all of them contain this word (`\"is\"`); so \n",
    "\n",
    "                                    idf(\"is\") = log(5 / 5) + 1 = 1\n",
    "\n",
    "2. The word `\"and\"`, we have\n",
    "\n",
    "                                    idf(\"and\") = log(5 / 1) + 1 appox 2.609 \n",
    "                                \n",
    "Noting that, the `log` here is `natural logarithm (default)`.\n",
    "\n",
    "***Note that the `idf` formula above differs from the standard textbook notation that defines the idf as***\n",
    "\n",
    "                                    idf(w) = log [ n / (df(w) + 1) ].\n",
    "\n",
    "- If `smooth_idf=True` (the default), the constant `“1”` is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which ***prevents zero divisions:*** \n",
    "\n",
    "                                    idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea_names</th>\n",
       "      <th>idf_smooth_False)</th>\n",
       "      <th>idf_smooth_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.182322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>second</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.182322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>third</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yours</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fea_names  idf_smooth_False)  idf_smooth_True\n",
       "0        and           2.609438         2.098612\n",
       "1   document           1.223144         1.182322\n",
       "2      first           1.916291         1.693147\n",
       "3         is           1.000000         1.000000\n",
       "4        not           2.609438         2.098612\n",
       "5        one           2.609438         2.098612\n",
       "6     second           2.609438         2.098612\n",
       "7        the           1.223144         1.182322\n",
       "8      third           2.609438         2.098612\n",
       "9       this           1.000000         1.000000\n",
       "10     yours           2.609438         2.098612"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('count', CountVectorizer(vocabulary = vocabulary, \n",
    "                                           min_df=2, max_df=0.5, ngram_range=(1,2))),\n",
    "                 ('tfid', TfidfTransformer(smooth_idf=True, use_idf=True))]).fit(corpus)\n",
    "\n",
    "table[\"idf_smooth_True\"] = pipe['tfid'].idf_\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6094379124341005, 2.09861228866811)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## verify the idf_value of the word \"and\"\n",
    "\n",
    "np.log(5) + 1, np.log((1 + 5)/(1+1))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the TFIDF score**, depend on how we compute the `idf_values`, the `tfidf` is defined by\n",
    "\n",
    "                                tf-idf(w, d) = tf(w, d) * idf(w)\n",
    "\n",
    "Recall that; the meaning of `TF` is **`term frequency`** and here defined by *the number of times that word `w` occurs in document `d`*\n",
    "\n",
    "For example; in the first sentence, `d = 1`; the word `\"and\"` is not in this sentence, so `tf(\"and\", d=1) = 0`.\n",
    "\n",
    "See the table bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea_names</th>\n",
       "      <th>idf_smooth_False)</th>\n",
       "      <th>idf_smooth_True</th>\n",
       "      <th>tfidf_smooth_True_1st_doc</th>\n",
       "      <th>tfidf_smooth_True_2nd_doc</th>\n",
       "      <th>tfidf_smooth_True_3rd_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.182322</td>\n",
       "      <td>0.427120</td>\n",
       "      <td>0.646126</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>0.611659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.361255</td>\n",
       "      <td>0.273244</td>\n",
       "      <td>0.245363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>second</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.182322</td>\n",
       "      <td>0.427120</td>\n",
       "      <td>0.323063</td>\n",
       "      <td>0.290099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>third</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.361255</td>\n",
       "      <td>0.273244</td>\n",
       "      <td>0.245363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yours</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fea_names  idf_smooth_False)  idf_smooth_True  tfidf_smooth_True_1st_doc  \\\n",
       "0        and           2.609438         2.098612                   0.000000   \n",
       "1   document           1.223144         1.182322                   0.427120   \n",
       "2      first           1.916291         1.693147                   0.611659   \n",
       "3         is           1.000000         1.000000                   0.361255   \n",
       "4        not           2.609438         2.098612                   0.000000   \n",
       "5        one           2.609438         2.098612                   0.000000   \n",
       "6     second           2.609438         2.098612                   0.000000   \n",
       "7        the           1.223144         1.182322                   0.427120   \n",
       "8      third           2.609438         2.098612                   0.000000   \n",
       "9       this           1.000000         1.000000                   0.361255   \n",
       "10     yours           2.609438         2.098612                   0.000000   \n",
       "\n",
       "    tfidf_smooth_True_2nd_doc  tfidf_smooth_True_3rd_doc  \n",
       "0                    0.000000                   0.514923  \n",
       "1                    0.646126                   0.000000  \n",
       "2                    0.000000                   0.000000  \n",
       "3                    0.273244                   0.245363  \n",
       "4                    0.000000                   0.000000  \n",
       "5                    0.000000                   0.514923  \n",
       "6                    0.573434                   0.000000  \n",
       "7                    0.323063                   0.290099  \n",
       "8                    0.000000                   0.514923  \n",
       "9                    0.273244                   0.245363  \n",
       "10                   0.000000                   0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = cvect.get_feature_names()\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary = vocabulary, \n",
    "                                           min_df=2, max_df=0.5, ngram_range=(1,2))),\n",
    "                 ('tfid', TfidfTransformer(smooth_idf=True, use_idf = True))]).fit(corpus)\n",
    "\n",
    "count_vector = pipe['count'].transform(corpus).toarray()  ## equivalent with CountVectorizer.fit_transform(corpus)\n",
    "\n",
    "tf_idf_vector = pipe['tfid'].transform(count_vector)\n",
    "tf_idf_vector[0].toarray()\n",
    "table[\"tfidf_smooth_True_1st_doc\"] = tf_idf_vector[0].T.toarray()\n",
    "table[\"tfidf_smooth_True_2nd_doc\"] = tf_idf_vector[1].T.toarray()\n",
    "table[\"tfidf_smooth_True_3rd_doc\"] = tf_idf_vector[2].T.toarray()\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. `TfidfVectorizer` is equivalent to the first method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'not', 'one', 'second', 'the', 'third', 'this', 'yours']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "tfidf_matrix =  tf.fit_transform(corpus)\n",
    "feature_names = tf.get_feature_names()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viewing the `tfidf-score` by using `TfidfVectorizer`; first looking at the `tfidf-values` in the first sentences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.42712001, 0.6116585 , 0.36125537, 0.        ,\n",
       "       0.        , 0.        , 0.42712001, 0.        , 0.36125537,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(corpus)\n",
    "M = tfidf_vectorizer_vectors.toarray()\n",
    "M[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf-idf values using Tfidfvectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea_names</th>\n",
       "      <th>tfidf_TfVec_1st_doc</th>\n",
       "      <th>tfidf_TfVec_2nd_doc</th>\n",
       "      <th>tfidf_TfVec_3rd_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document</td>\n",
       "      <td>0.427120</td>\n",
       "      <td>0.646126</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first</td>\n",
       "      <td>0.611659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>0.361255</td>\n",
       "      <td>0.273244</td>\n",
       "      <td>0.245363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>second</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>0.427120</td>\n",
       "      <td>0.323063</td>\n",
       "      <td>0.290099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>third</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this</td>\n",
       "      <td>0.361255</td>\n",
       "      <td>0.273244</td>\n",
       "      <td>0.245363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yours</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fea_names  tfidf_TfVec_1st_doc  tfidf_TfVec_2nd_doc  tfidf_TfVec_3rd_doc\n",
       "0        and             0.000000             0.000000             0.514923\n",
       "1   document             0.427120             0.646126             0.000000\n",
       "2      first             0.611659             0.000000             0.000000\n",
       "3         is             0.361255             0.273244             0.245363\n",
       "4        not             0.000000             0.000000             0.000000\n",
       "5        one             0.000000             0.000000             0.514923\n",
       "6     second             0.000000             0.573434             0.000000\n",
       "7        the             0.427120             0.323063             0.290099\n",
       "8      third             0.000000             0.000000             0.514923\n",
       "9       this             0.361255             0.273244             0.245363\n",
       "10     yours             0.000000             0.000000             0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"fea_names\": feature_names, \n",
    "              \"tfidf_TfVec_1st_doc\": M[0, :], \n",
    "              \"tfidf_TfVec_2nd_doc\": M[1, :],\n",
    "              \"tfidf_TfVec_3rd_doc\": M[2, :]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a summary, the main difference between the two modules are as follows:\n",
    "\n",
    "- With `Tfidftransformer` you will systematically compute word counts using `CountVectorizer` and then compute the `Inverse Document Frequency (IDF)` values and only then compute the `Tf-idf scores`.\n",
    "\n",
    "- With `Tfidfvectorizer` on the contrary, **you will do all three steps at once**. It computes the word counts, IDF values, and Tf-idf scores all using the same dataset.\n",
    "\n",
    "**When to use what?**\n",
    "So now you may be wondering, why you should use more steps than necessary if you can get everything done in two steps. Well, there are cases where you want to use Tfidftransformer over Tfidfvectorizer and it is sometimes not that obvious. Here is a general guideline:\n",
    "\n",
    "- If you need the `term frequency` (term count) vectors for `different tasks`, use `Tfidftransformer`.\n",
    "- If you need to compute `tf-idf scores` on documents within your `“training”` dataset, use `Tfidfvectorizer`.\n",
    "- If you need to compute `tf-idf scores` on documents **`outside your “training”`** dataset, use either one, both will work.\n",
    "\n",
    "### 1.3. Co-occurrence Matrix.\n",
    "\n",
    "A co-occurrence matrix or co-occurrence distribution is a matrix that is defined over an image to be the distribution of co-occurring pixel values (grayscale values, or colors) at a given offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "import itertools\n",
    "\n",
    "def generate_co_occurrence_matrix(corpus):\n",
    "    \n",
    "    ## Create the vocabulary_list, set and indexes\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    " \n",
    "    # Create bigrams from all words in corpus\n",
    "    bi_grams = list(bigrams(corpus))\n",
    " \n",
    "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    " \n",
    "    # Initialise co-occurrence matrix\n",
    "    # co_occurrence_matrix[current][previous]\n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
    " \n",
    "    # Loop through the bigrams taking the current and previous word,\n",
    "    # and the number of occurrences of the bigram.\n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "        pos_current = vocab_index[current]\n",
    "        pos_previous = vocab_index[previous]\n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "    \n",
    "    # create matrix\n",
    "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
    " \n",
    "    # return the matrix and the index\n",
    "    return co_occurrence_matrix, vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>never</th>\n",
       "      <th>because</th>\n",
       "      <th>up</th>\n",
       "      <th>give</th>\n",
       "      <th>say</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         never  because   up  give  say\n",
       "never      0.0      1.0  0.0   0.0  1.0\n",
       "because    1.0      0.0  0.0   0.0  0.0\n",
       "up         0.0      0.0  0.0   1.0  0.0\n",
       "give       1.0      0.0  0.0   0.0  0.0\n",
       "say        1.0      0.0  0.0   0.0  0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1 = [[\"never\", \"say\", \"never\", \"because\", \"never\", \"give\", \"up\"]]\n",
    "\n",
    "# Create one list using many lists\n",
    "data = list(itertools.chain.from_iterable(text_1))\n",
    "matrix, vocab_index = generate_co_occurrence_matrix(data)\n",
    "  \n",
    "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
    "                             columns=vocab_index)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Why</th>\n",
       "      <th>companies</th>\n",
       "      <th>is</th>\n",
       "      <th>now</th>\n",
       "      <th>When</th>\n",
       "      <th>What</th>\n",
       "      <th>begining</th>\n",
       "      <th>used</th>\n",
       "      <th>Where</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>ok</th>\n",
       "      <th>Python</th>\n",
       "      <th>there</th>\n",
       "      <th>tall</th>\n",
       "      <th>but</th>\n",
       "      <th>use</th>\n",
       "      <th>In</th>\n",
       "      <th>Adam</th>\n",
       "      <th>did</th>\n",
       "      <th>of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Why</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>companies</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>now</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>When</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>begining</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leave</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>there</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Why  companies   is  now  When  What  begining  used  Where  are  \\\n",
       "Why        0.0        0.0  0.0  1.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "companies  0.0        0.0  0.0  0.0   0.0   1.0       0.0   0.0    0.0  0.0   \n",
       "is         0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "now        0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "When       0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "What       0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "begining   0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "used       0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "Where      0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "are        0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    1.0  0.0   \n",
       "leave      0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "the        0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "you        0.0        0.0  0.0  0.0   1.0   0.0       0.0   0.0    0.0  1.0   \n",
       "Jane       0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "fat        0.0        0.0  1.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "ok         0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "Python     0.0        0.0  0.0  0.0   0.0   0.0       0.0   1.0    0.0  0.0   \n",
       "there      0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "tall       0.0        0.0  1.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "but        0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "use        0.0        1.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "In         0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "Adam       0.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "did        1.0        0.0  0.0  0.0   0.0   0.0       0.0   0.0    0.0  0.0   \n",
       "of         0.0        0.0  0.0  0.0   0.0   0.0       1.0   0.0    0.0  0.0   \n",
       "\n",
       "           ...   ok  Python  there  tall  but  use   In  Adam  did   of  \n",
       "Why        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "companies  ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "is         ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   1.0  0.0  0.0  \n",
       "now        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "When       ...  0.0     1.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "What       ...  0.0     0.0    1.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "begining   ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "used       ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "Where      ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "are        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "leave      ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "the        ...  0.0     0.0    0.0   0.0  0.0  0.0  1.0   0.0  0.0  0.0  \n",
       "you        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  1.0  0.0  \n",
       "Jane       ...  1.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "fat        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "ok         ...  0.0     1.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "Python     ...  0.0     0.0    0.0   0.0  0.0  1.0  0.0   0.0  0.0  1.0  \n",
       "there      ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "tall       ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "but        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "use        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "In         ...  0.0     1.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "Adam       ...  0.0     0.0    0.0   0.0  1.0  0.0  0.0   0.0  0.0  0.0  \n",
       "did        ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "of         ...  0.0     0.0    0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "\n",
       "[25 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2 = [['Where', 'are', 'you', 'now'],\n",
    "             ['Why', 'did', 'you', 'used', 'Python'],\n",
    "             ['When', 'you', 'leave', 'there'],\n",
    "             ['What', 'companies', 'use', 'Python'],\n",
    "             ['In', 'the', 'begining', 'of', 'Python'],\n",
    "             [\"ok\", \"Jane\", \"is\", \"fat\", \"but\", \"Adam\", \"is\", \"tall\"]]\n",
    " \n",
    "data = list(itertools.chain.from_iterable(text_2))\n",
    "matrix, vocab_index = generate_co_occurrence_matrix(data)\n",
    "  \n",
    "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
    "                             columns=vocab_index)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
