{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 0. List files in input_folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# print out the names of the first 2 image_files (total = 4 images for train_imgaes & train_label_masks) with the train, test, submission.csv files & 5 file.hdf5\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:2]:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv\n/kaggle/input/prostate-cancer-grade-assessment/test.csv\n/kaggle/input/prostate-cancer-grade-assessment/train_images/a05ded7fe107cfdfcfc8f644fb2d7313.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_images/72e64850d127c65815492af84473a26e.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_label_masks/aa7000449538fe951e1c0dadc7ce9b44_mask.tiff\n/kaggle/input/prostate-cancer-grade-assessment/train_label_masks/d63c41a88f43f4f46b49fe4d63c9d117_mask.tiff\n/kaggle/input/radboud-database/radboud_tiles_coordinates.h5\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Naming the directories"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport openslide\nimport skimage.io\nimport random\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nfrom IPython.display import Image, display\n\nBASE_PATH = '../input/prostate-cancer-grade-assessment'\ndata_dir = f'{BASE_PATH}/train_images'\nmask_dir = f'{BASE_PATH}/train_label_masks'\nhdf5_dir = r'/kaggle/input/radboud-database/radboud_tiles_coordinates.h5'","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Load database"},{"metadata":{"trusted":true},"cell_type":"code","source":"import deepdish as dd\n\ndf = dd.io.load(hdf5_dir)\nlen(df)//36, len(df[0]), df[0], len(df)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(4664,\n 5,\n ['0018ae58b01bdadc8e347995b69f99aa', 14336, 14848, 2048, 2560],\n 167904)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 2. Create the class to load PANDA_dataset with this database"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data_and_mask(ID, coordinates, level = 1):\n    \"\"\"\n    Input args:\n        ID (str): img_id from the dataset\n        coordinates (list of int): list of coordinates, includes: [x_start, x_end, y_start, y_end] from h5.database\n        level (={0, 1, 2}) : level of images for loading with skimage\n    Return: 3D tiles shape 512x512 of the mask images and data images w.r.t the input_coordinates, ID and level\n    \"\"\"\n    data_img = skimage.io.MultiImage(os.path.join(data_dir, f'{ID}.tiff'))[level]\n    mask_img = skimage.io.MultiImage(os.path.join(mask_dir, f'{ID}_mask.tiff'))[level]\n    coordinates = [coordinate // 2**(2*level) for coordinate in coordinates]\n    data_tile = data_img[coordinates[0]: coordinates[1], coordinates[2]: coordinates[3], :]\n    mask_tile = mask_img[coordinates[0]: coordinates[1], coordinates[2]: coordinates[3], :]\n    data_tile = cv2.resize(data_tile, (512, 512))\n    mask_tile = cv2.resize(mask_tile, (512, 512))\n    del data_img, mask_img\n    \n    # Load and return small image\n    return data_tile, mask_tile","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First trying with the first `3500 (img_id)` or `126000 (tiles)`"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\n\nclass PANDADataset(Dataset):\n    def __init__(self, df, level = 2, transform=None):\n        self.df = df\n        self.level = level\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, index, level = 2):\n        ID = self.df[index][0]\n        coordinate = self.df[index][1: ]\n        image, mask = load_data_and_mask(ID, coordinate, level)\n        \n        return torch.tensor(image).permute(2, 0, 1), torch.tensor(mask).permute(2, 0, 1)[0]\n    \ncls = PANDADataset(df, 1)\n%time cls[0][0].size(), cls[0][1].size(), len(cls)","execution_count":5,"outputs":[{"output_type":"stream","text":"CPU times: user 45.6 ms, sys: 7.69 ms, total: 53.3 ms\nWall time: 119 ms\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(torch.Size([3, 512, 512]), torch.Size([512, 512]), 167904)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 3. Build the model\n\nAdapted from https://discuss.pytorch.org/t/unet-implementation/426"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataLoader = DataLoader(cls, batch_size=8, shuffle=True, num_workers=8)\ndel df, cls\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=1, n_classes=2, depth=5, wf=6, padding=False,\n                 batch_norm=False, up_mode='upconv'):\n        \"\"\"\n        Implementation of\n        U-Net: Convolutional Networks for Biomedical Image Segmentation\n        (Ronneberger et al., 2015)\n        https://arxiv.org/abs/1505.04597\n        Using the default arguments will yield the exact version used\n        in the original paper\n        Args:\n            in_channels (int): number of input channels\n            n_classes (int): number of output channels\n            depth (int): depth of the network\n            wf (int): number of filters in the first layer is 2**wf\n            padding (bool): if True, apply padding such that the input shape\n                            is the same as the output.\n                            This may introduce artifacts\n            batch_norm (bool): Use BatchNorm after layers with an\n                               activation function\n            up_mode (str): one of 'upconv' or 'upsample'.\n                           'upconv' will use transposed convolutions for\n                           learned upsampling.\n                           'upsample' will use bilinear upsampling.\n        \"\"\"\n        super(UNet, self).__init__()\n        assert up_mode in ('upconv', 'upsample')\n        self.padding = padding\n        self.depth = depth\n        prev_channels = in_channels\n        self.down_path = nn.ModuleList()\n        for i in range(depth):\n            self.down_path.append(UNetConvBlock(prev_channels, 2**(wf+i),\n                                                padding, batch_norm))\n            prev_channels = 2**(wf+i)\n\n        self.up_path = nn.ModuleList()\n        for i in reversed(range(depth - 1)):\n            self.up_path.append(UNetUpBlock(prev_channels, 2**(wf+i), up_mode,\n                                            padding, batch_norm))\n            prev_channels = 2**(wf+i)\n\n        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n\n    def forward(self, x):\n        blocks = []\n        for i, down in enumerate(self.down_path):\n            x = down(x)\n            if i != len(self.down_path)-1:\n                blocks.append(x)\n                x = F.avg_pool2d(x, 2)\n\n        for i, up in enumerate(self.up_path):\n            x = up(x, blocks[-i-1])\n\n        return self.last(x)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class UNetConvBlock(nn.Module):\n    def __init__(self, in_size, out_size, padding, batch_norm):\n        super(UNetConvBlock, self).__init__()\n        block = []\n\n        block.append(nn.Conv2d(in_size, out_size, kernel_size=3,\n                               padding=int(padding)))\n        block.append(nn.ReLU())\n        if batch_norm:\n            block.append(nn.BatchNorm2d(out_size))\n\n        block.append(nn.Conv2d(out_size, out_size, kernel_size=3,\n                               padding=int(padding)))\n        block.append(nn.ReLU())\n        if batch_norm:\n            block.append(nn.BatchNorm2d(out_size))\n\n        self.block = nn.Sequential(*block)\n\n    def forward(self, x):\n        out = self.block(x)\n        return out","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class UNetUpBlock(nn.Module):\n    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n        super(UNetUpBlock, self).__init__()\n        if up_mode == 'upconv':\n            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2,\n                                         stride=2)\n        elif up_mode == 'upsample':\n            self.up = nn.Sequential(nn.Upsample(mode='bilinear', scale_factor=2),\n                                    nn.Conv2d(in_size, out_size, kernel_size=1))\n\n        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n\n    def center_crop(self, layer, target_size):\n        _, _, layer_height, layer_width = layer.size()\n        diff_y = (layer_height - target_size[0]) // 2\n        diff_x = (layer_width - target_size[1]) // 2\n        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n\n    def forward(self, x, bridge):\n        up = self.up(x)\n        crop1 = self.center_crop(bridge, up.shape[2:])\n        out = torch.cat([up, crop1], 1)\n        out = self.conv_block(out)\n\n        return out","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### `Unet`-params & training params\n\nThese parameters get fed directly into the UNET class, and more description of them can be discovered there\n\nBut here, I will try with epochs = 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# --- Unet params\nn_classes= 6    # number of classes in the data mask that we'll aim to predict\n\n\nin_channels = 3  # input channel of the data, RGB = 3\npadding = True   # should levels be padded\ndepth = 5        # depth of the network \nwf = 2           # wf (int): number of filters in the first layer is 2**wf, was 6\nup_mode = 'upconv' #should we simply upsample the mask, or should we try and learn an interpolation \nbatch_norm = True #should we use batch normalization between the layers\n\n# --- training params\n\nbatch_size = 8\npatch_size = 512\nnum_epochs = 5\nedge_weight = 1.1 # edges tend to be the most poorly segmented given how little area they occupy in the training set, this paramter boosts their values along the lines of the original UNET paper\nphases = [\"train\",\"val\"] # how many phases did we create databases for?\nvalidation_phases= [\"val\"] # when should we do valiation? note that validation is time consuming, so as opposed to doing for both training and validation, we do it only for vlaidation at the end of the epoch","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Decide what divice to run the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"gpuid = 0\nif(torch.cuda.is_available()):\n    print(torch.cuda.get_device_properties(gpuid))\n    torch.cuda.set_device(gpuid)\n    device = torch.device(f'cuda:{gpuid}')\nelse:\n    device = torch.device(f'cpu')","execution_count":10,"outputs":[{"output_type":"stream","text":"_CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 5. Fit the model according to the paramters specified above and copy it to the GPU.\n\nThen finally print out the number of trainable parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = UNet(n_classes = n_classes, in_channels = in_channels, \n             padding = padding, depth = depth, wf = wf, \n             up_mode = up_mode, batch_norm = batch_norm).to(device)\nprint(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")\n\noptim = torch.optim.Adam(model.parameters()) #adam is going to be the most robust\ncriterion = nn.CrossEntropyLoss(reduce=False)","execution_count":11,"outputs":[{"output_type":"stream","text":"total params: \t122486\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n  warnings.warn(warning.format(ret))\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"#### Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nprint('========================================== Training started ==========================================')\nfor epoch in range(num_epochs):\n    print('======================================================================================================')\n    #model.train()  # Set model to training mode\n    running_loss = 0.0\n    t0 = time.time()\n    for i, data in enumerate(dataLoader, 0):\n        inputs, labels = data\n        inputs = inputs.to(device,dtype = torch.float) \n        labels = labels.type('torch.LongTensor').to(device)\n        \n        # zero the parameter gradients\n        optim.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        loss.sum().backward()\n        optim.step()\n        \n        # print statistics\n        running_loss += loss.mean()\n        \n        if i % 1000 == 999:    # print every 1000 mini-batches\n            t1 = time.time()\n            h = (t1 - t0) // 3600\n            m = (t1 - t0 - h*3600) // 60\n            s = (t1 - t0) % 60\n            print('Epoch %02d, upto %05d mini-batches; after %02d (hours) %02d (minutes) and %02d (seconds);  train_loss = %.3f'%\n                  (epoch + 1, i + 1, h, m, s, running_loss / 1000))\n            running_loss = 0.0\nprint('======================================================================================================')\nprint('========================================== Finished Training =========================================')","execution_count":12,"outputs":[{"output_type":"stream","text":"========================================== Training started ==========================================\n======================================================================================================\nEpoch 01, upto 01000 mini-batches; after 00 (hours) 02 (minutes) and 55 (seconds);  train_loss = 1.206\nEpoch 01, upto 02000 mini-batches; after 00 (hours) 05 (minutes) and 45 (seconds);  train_loss = 0.935\nEpoch 01, upto 03000 mini-batches; after 00 (hours) 08 (minutes) and 35 (seconds);  train_loss = 0.918\nEpoch 01, upto 04000 mini-batches; after 00 (hours) 11 (minutes) and 29 (seconds);  train_loss = 0.908\nEpoch 01, upto 05000 mini-batches; after 00 (hours) 14 (minutes) and 24 (seconds);  train_loss = 0.883\nEpoch 01, upto 06000 mini-batches; after 00 (hours) 17 (minutes) and 19 (seconds);  train_loss = 0.886\nEpoch 01, upto 07000 mini-batches; after 00 (hours) 20 (minutes) and 14 (seconds);  train_loss = 0.869\nEpoch 01, upto 08000 mini-batches; after 00 (hours) 23 (minutes) and 14 (seconds);  train_loss = 0.867\nEpoch 01, upto 09000 mini-batches; after 00 (hours) 26 (minutes) and 13 (seconds);  train_loss = 0.833\nEpoch 01, upto 10000 mini-batches; after 00 (hours) 29 (minutes) and 16 (seconds);  train_loss = 0.829\nEpoch 01, upto 11000 mini-batches; after 00 (hours) 32 (minutes) and 17 (seconds);  train_loss = 0.830\nEpoch 01, upto 12000 mini-batches; after 00 (hours) 35 (minutes) and 16 (seconds);  train_loss = 0.813\nEpoch 01, upto 13000 mini-batches; after 00 (hours) 38 (minutes) and 11 (seconds);  train_loss = 0.811\nEpoch 01, upto 14000 mini-batches; after 00 (hours) 41 (minutes) and 07 (seconds);  train_loss = 0.803\nEpoch 01, upto 15000 mini-batches; after 00 (hours) 44 (minutes) and 07 (seconds);  train_loss = 0.803\nEpoch 01, upto 16000 mini-batches; after 00 (hours) 46 (minutes) and 59 (seconds);  train_loss = 0.793\nEpoch 01, upto 17000 mini-batches; after 00 (hours) 49 (minutes) and 51 (seconds);  train_loss = 0.781\nEpoch 01, upto 18000 mini-batches; after 00 (hours) 52 (minutes) and 43 (seconds);  train_loss = 0.779\nEpoch 01, upto 19000 mini-batches; after 00 (hours) 55 (minutes) and 36 (seconds);  train_loss = 0.768\nEpoch 01, upto 20000 mini-batches; after 00 (hours) 58 (minutes) and 28 (seconds);  train_loss = 0.764\n======================================================================================================\nEpoch 02, upto 01000 mini-batches; after 00 (hours) 02 (minutes) and 55 (seconds);  train_loss = 0.747\nEpoch 02, upto 02000 mini-batches; after 00 (hours) 05 (minutes) and 47 (seconds);  train_loss = 0.752\nEpoch 02, upto 03000 mini-batches; after 00 (hours) 08 (minutes) and 41 (seconds);  train_loss = 0.749\nEpoch 02, upto 04000 mini-batches; after 00 (hours) 11 (minutes) and 33 (seconds);  train_loss = 0.737\nEpoch 02, upto 05000 mini-batches; after 00 (hours) 14 (minutes) and 27 (seconds);  train_loss = 0.737\nEpoch 02, upto 06000 mini-batches; after 00 (hours) 17 (minutes) and 21 (seconds);  train_loss = 0.744\nEpoch 02, upto 07000 mini-batches; after 00 (hours) 20 (minutes) and 15 (seconds);  train_loss = 0.752\nEpoch 02, upto 08000 mini-batches; after 00 (hours) 23 (minutes) and 08 (seconds);  train_loss = 0.750\nEpoch 02, upto 09000 mini-batches; after 00 (hours) 26 (minutes) and 01 (seconds);  train_loss = 0.728\nEpoch 02, upto 10000 mini-batches; after 00 (hours) 28 (minutes) and 55 (seconds);  train_loss = 0.743\nEpoch 02, upto 11000 mini-batches; after 00 (hours) 31 (minutes) and 50 (seconds);  train_loss = 0.728\nEpoch 02, upto 12000 mini-batches; after 00 (hours) 34 (minutes) and 45 (seconds);  train_loss = 0.725\nEpoch 02, upto 13000 mini-batches; after 00 (hours) 37 (minutes) and 39 (seconds);  train_loss = 0.720\nEpoch 02, upto 14000 mini-batches; after 00 (hours) 40 (minutes) and 32 (seconds);  train_loss = 0.719\nEpoch 02, upto 15000 mini-batches; after 00 (hours) 43 (minutes) and 24 (seconds);  train_loss = 0.721\nEpoch 02, upto 16000 mini-batches; after 00 (hours) 46 (minutes) and 13 (seconds);  train_loss = 0.731\nEpoch 02, upto 17000 mini-batches; after 00 (hours) 49 (minutes) and 03 (seconds);  train_loss = 0.726\nEpoch 02, upto 18000 mini-batches; after 00 (hours) 51 (minutes) and 53 (seconds);  train_loss = 0.717\nEpoch 02, upto 19000 mini-batches; after 00 (hours) 54 (minutes) and 43 (seconds);  train_loss = 0.737\nEpoch 02, upto 20000 mini-batches; after 00 (hours) 57 (minutes) and 34 (seconds);  train_loss = 0.712\n======================================================================================================\nEpoch 03, upto 01000 mini-batches; after 00 (hours) 02 (minutes) and 50 (seconds);  train_loss = 0.710\nEpoch 03, upto 02000 mini-batches; after 00 (hours) 05 (minutes) and 40 (seconds);  train_loss = 0.709\nEpoch 03, upto 03000 mini-batches; after 00 (hours) 08 (minutes) and 29 (seconds);  train_loss = 0.715\nEpoch 03, upto 04000 mini-batches; after 00 (hours) 11 (minutes) and 19 (seconds);  train_loss = 0.709\nEpoch 03, upto 05000 mini-batches; after 00 (hours) 14 (minutes) and 11 (seconds);  train_loss = 0.728\nEpoch 03, upto 06000 mini-batches; after 00 (hours) 17 (minutes) and 02 (seconds);  train_loss = 0.717\nEpoch 03, upto 07000 mini-batches; after 00 (hours) 19 (minutes) and 54 (seconds);  train_loss = 0.718\nEpoch 03, upto 08000 mini-batches; after 00 (hours) 22 (minutes) and 44 (seconds);  train_loss = 0.729\nEpoch 03, upto 09000 mini-batches; after 00 (hours) 25 (minutes) and 35 (seconds);  train_loss = 0.702\nEpoch 03, upto 10000 mini-batches; after 00 (hours) 28 (minutes) and 26 (seconds);  train_loss = 0.712\nEpoch 03, upto 11000 mini-batches; after 00 (hours) 31 (minutes) and 18 (seconds);  train_loss = 0.692\nEpoch 03, upto 12000 mini-batches; after 00 (hours) 34 (minutes) and 08 (seconds);  train_loss = 0.708\nEpoch 03, upto 13000 mini-batches; after 00 (hours) 36 (minutes) and 58 (seconds);  train_loss = 0.718\nEpoch 03, upto 14000 mini-batches; after 00 (hours) 39 (minutes) and 51 (seconds);  train_loss = 0.703\nEpoch 03, upto 15000 mini-batches; after 00 (hours) 42 (minutes) and 41 (seconds);  train_loss = 0.698\nEpoch 03, upto 16000 mini-batches; after 00 (hours) 45 (minutes) and 29 (seconds);  train_loss = 0.706\nEpoch 03, upto 17000 mini-batches; after 00 (hours) 48 (minutes) and 18 (seconds);  train_loss = 0.701\nEpoch 03, upto 18000 mini-batches; after 00 (hours) 51 (minutes) and 09 (seconds);  train_loss = 0.706\nEpoch 03, upto 19000 mini-batches; after 00 (hours) 54 (minutes) and 01 (seconds);  train_loss = 0.726\nEpoch 03, upto 20000 mini-batches; after 00 (hours) 56 (minutes) and 54 (seconds);  train_loss = 0.700\n======================================================================================================\nEpoch 04, upto 01000 mini-batches; after 00 (hours) 02 (minutes) and 55 (seconds);  train_loss = 0.702\nEpoch 04, upto 02000 mini-batches; after 00 (hours) 05 (minutes) and 46 (seconds);  train_loss = 0.704\nEpoch 04, upto 03000 mini-batches; after 00 (hours) 08 (minutes) and 38 (seconds);  train_loss = 0.698\nEpoch 04, upto 04000 mini-batches; after 00 (hours) 11 (minutes) and 29 (seconds);  train_loss = 0.701\nEpoch 04, upto 05000 mini-batches; after 00 (hours) 14 (minutes) and 22 (seconds);  train_loss = 0.696\nEpoch 04, upto 06000 mini-batches; after 00 (hours) 17 (minutes) and 14 (seconds);  train_loss = 0.703\nEpoch 04, upto 07000 mini-batches; after 00 (hours) 20 (minutes) and 05 (seconds);  train_loss = 0.697\nEpoch 04, upto 08000 mini-batches; after 00 (hours) 22 (minutes) and 58 (seconds);  train_loss = 0.701\nEpoch 04, upto 09000 mini-batches; after 00 (hours) 25 (minutes) and 47 (seconds);  train_loss = 0.697\nEpoch 04, upto 10000 mini-batches; after 00 (hours) 28 (minutes) and 37 (seconds);  train_loss = 0.699\nEpoch 04, upto 11000 mini-batches; after 00 (hours) 31 (minutes) and 27 (seconds);  train_loss = 0.696\nEpoch 04, upto 12000 mini-batches; after 00 (hours) 34 (minutes) and 18 (seconds);  train_loss = 0.679\nEpoch 04, upto 13000 mini-batches; after 00 (hours) 37 (minutes) and 07 (seconds);  train_loss = 0.697\nEpoch 04, upto 14000 mini-batches; after 00 (hours) 39 (minutes) and 58 (seconds);  train_loss = 0.693\nEpoch 04, upto 15000 mini-batches; after 00 (hours) 42 (minutes) and 47 (seconds);  train_loss = 0.695\n","name":"stdout"},{"output_type":"stream","text":"Epoch 04, upto 16000 mini-batches; after 00 (hours) 45 (minutes) and 38 (seconds);  train_loss = 0.700\nEpoch 04, upto 17000 mini-batches; after 00 (hours) 48 (minutes) and 28 (seconds);  train_loss = 0.691\nEpoch 04, upto 18000 mini-batches; after 00 (hours) 51 (minutes) and 18 (seconds);  train_loss = 0.685\nEpoch 04, upto 19000 mini-batches; after 00 (hours) 54 (minutes) and 08 (seconds);  train_loss = 0.695\nEpoch 04, upto 20000 mini-batches; after 00 (hours) 56 (minutes) and 57 (seconds);  train_loss = 0.697\n======================================================================================================\nEpoch 05, upto 01000 mini-batches; after 00 (hours) 02 (minutes) and 51 (seconds);  train_loss = 0.704\nEpoch 05, upto 02000 mini-batches; after 00 (hours) 05 (minutes) and 39 (seconds);  train_loss = 0.690\nEpoch 05, upto 03000 mini-batches; after 00 (hours) 08 (minutes) and 27 (seconds);  train_loss = 0.680\nEpoch 05, upto 04000 mini-batches; after 00 (hours) 11 (minutes) and 16 (seconds);  train_loss = 0.682\nEpoch 05, upto 05000 mini-batches; after 00 (hours) 14 (minutes) and 04 (seconds);  train_loss = 0.685\nEpoch 05, upto 06000 mini-batches; after 00 (hours) 16 (minutes) and 53 (seconds);  train_loss = 0.692\nEpoch 05, upto 07000 mini-batches; after 00 (hours) 19 (minutes) and 43 (seconds);  train_loss = 0.685\nEpoch 05, upto 08000 mini-batches; after 00 (hours) 22 (minutes) and 32 (seconds);  train_loss = 0.677\nEpoch 05, upto 09000 mini-batches; after 00 (hours) 25 (minutes) and 21 (seconds);  train_loss = 0.683\nEpoch 05, upto 10000 mini-batches; after 00 (hours) 28 (minutes) and 10 (seconds);  train_loss = 0.695\nEpoch 05, upto 11000 mini-batches; after 00 (hours) 30 (minutes) and 58 (seconds);  train_loss = 0.682\nEpoch 05, upto 12000 mini-batches; after 00 (hours) 33 (minutes) and 48 (seconds);  train_loss = 0.688\nEpoch 05, upto 13000 mini-batches; after 00 (hours) 36 (minutes) and 39 (seconds);  train_loss = 0.681\nEpoch 05, upto 14000 mini-batches; after 00 (hours) 39 (minutes) and 32 (seconds);  train_loss = 0.682\nEpoch 05, upto 15000 mini-batches; after 00 (hours) 42 (minutes) and 23 (seconds);  train_loss = 0.683\nEpoch 05, upto 16000 mini-batches; after 00 (hours) 45 (minutes) and 13 (seconds);  train_loss = 0.688\nEpoch 05, upto 17000 mini-batches; after 00 (hours) 48 (minutes) and 00 (seconds);  train_loss = 0.673\nEpoch 05, upto 18000 mini-batches; after 00 (hours) 53 (minutes) and 45 (seconds);  train_loss = 0.682\nEpoch 05, upto 19000 mini-batches; after 01 (hours) 04 (minutes) and 14 (seconds);  train_loss = 0.683\nEpoch 05, upto 20000 mini-batches; after 01 (hours) 09 (minutes) and 56 (seconds);  train_loss = 0.682\n======================================================================================================\n========================================== Finished Training =========================================\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"315"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Evaluation\n\n(I will do it later in the next few days) !!!"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}