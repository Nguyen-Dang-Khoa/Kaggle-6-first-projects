{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Import the libraries`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Loading & Viewing dataset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1\n",
       "5  #RockyFire Update => California Hwy. 20 closed...       1\n",
       "6  #flood #disaster Heavy rain causes flash flood...       1\n",
       "7  I'm on top of the hill and I can see a fire in...       1\n",
       "8  There's an emergency evacuation happening now ...       1\n",
       "9  I'm afraid that the tornado is coming to our a...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"./train.csv\", usecols=[\"text\", \"target\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_names : \\ttext', 'col_names : \\ttarget'], dtype='object')\n",
      "\n",
      "\n",
      "Data-dimensions: \t(7613, 2)\n",
      "\n",
      "\n",
      "Count the not-null values of each features: \n",
      "text      7613\n",
      "target    7613\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"col_names : \\t\" + df.columns)\n",
    "print('\\n')\n",
    "print(\"Data-dimensions: \\t\" + str(df.shape))\n",
    "print('\\n')\n",
    "print(\"Count the not-null values of each features: \\n\" + str(df.notnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Checking for duplicates and removing them`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new dimension after checking duplicate & removing is:\t(7521, 2)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "print(\"The new dimension after checking duplicate & removing is:\\t\" + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create a function to clean the text and return the tokens. The cleaning of the text can be done by first removing punctuations and then removing the useless words also known as stop words.`\n",
    "\n",
    "**`Tokenization`** (a list of tokens), will be used as the analyzer\n",
    "\n",
    "`1.Punctuations`, such as `[!\"#$%&'()*+,-./:;<=>?@[\\]^_``{|}~]`\n",
    "\n",
    "`2.Stop words` in natural language processing, are useless words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Viewing the punctuation in string_package`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Build a function`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    '''\n",
    "    What will be covered:\n",
    "    1. Remove punctuation\n",
    "    2. Remove stopwords\n",
    "    3. Return list of clean text words\n",
    "    '''\n",
    "    \n",
    "    #1\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    #2\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "        \n",
    "    #3\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Deeds, Reason, earthquake, May, ALLAH, Forgiv...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, Canada]\n",
       "2    [residents, asked, shelter, place, notified, o...\n",
       "3    [13000, people, receive, wildfires, evacuation...\n",
       "4    [got, sent, photo, Ruby, Alaska, smoke, wildfi...\n",
       "5    [RockyFire, Update, California, Hwy, 20, close...\n",
       "6    [flood, disaster, Heavy, rain, causes, flash, ...\n",
       "7                    [Im, top, hill, see, fire, woods]\n",
       "8    [Theres, emergency, evacuation, happening, bui...\n",
       "9                  [Im, afraid, tornado, coming, area]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head(10).apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Remove the links (such as url, html)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "## Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Build a function to correct the wrong-word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Deeds, Reason, earthquake, May, ALLAH, Forgiv...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, Canada]\n",
       "2    [residents, asked, shelter, place, notified, o...\n",
       "3    [r3000, people, receive, wildfire, evacuation,...\n",
       "4    [got, sent, photo, Ruby, Alaska, smoke, wildfi...\n",
       "5    [RockyFire, Update, California, Hwy, 20, close...\n",
       "6    [flood, disaster, Heavy, rain, causes, flash, ...\n",
       "7                    [Im, top, hill, see, fire, woods]\n",
       "8    [Theres, emergency, evacuation, happening, bui...\n",
       "9                  [Im, afraid, tornado, coming, area]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)        \n",
    "\n",
    "df['text'].head(10).apply(correct_spellings).apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text_process = CountVectorizer(analyzer = process_text).fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_process, df['target'], \n",
    "                                                    test_size = 0.20, \n",
    "                                                    stratify = df['target'], \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7521, 26473)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the shape of text_process\n",
    "text_process.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 0]\n",
      "\n",
      "\n",
      "[1 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Print the predictions\n",
    "print(classifier.predict(X_train))\n",
    "print('\\n')\n",
    "#Print the actual values\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      3452\n",
      "           1       0.96      0.90      0.93      2564\n",
      "\n",
      "    accuracy                           0.94      6016\n",
      "   macro avg       0.95      0.94      0.94      6016\n",
      "weighted avg       0.94      0.94      0.94      6016\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3368   84]\n",
      " [ 268 2296]]\n",
      "\n",
      "Accuracy:  0.9414893617021277\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "pred = classifier.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_train, pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value:  [1 1 1 ... 0 1 0]\n",
      "Actual value:  [0 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Print the predictions\n",
    "print('Predicted value: ',classifier.predict(X_test))\n",
    "#Print Actual Label\n",
    "print('Actual value: ',y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       863\n",
      "           1       0.76      0.73      0.74       642\n",
      "\n",
      "    accuracy                           0.78      1505\n",
      "   macro avg       0.78      0.78      0.78      1505\n",
      "weighted avg       0.78      0.78      0.78      1505\n",
      "\n",
      "Confusion Matrix: \n",
      " [[714 149]\n",
      " [175 467]]\n",
      "\n",
      "Accuracy:  0.7847176079734219\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Hence, based on the accuracy (train & test); then we must to modify this overfitting!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
